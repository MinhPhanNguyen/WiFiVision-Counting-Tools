import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os

def check_csi_data(file_path):
    """
    Ki·ªÉm tra t√≠nh ch√≠nh x√°c v√† ph√°t hi·ªán l·ªói trong d·ªØ li·ªáu CSI
    """
    print(f"=== KI·ªÇM TRA FILE: {file_path} ===")
    
    try:
        # ƒê·ªçc file CSV v·ªõi x·ª≠ l√Ω l·ªói
        try:
            df = pd.read_csv(file_path)
        except pd.errors.ParserError as e:
            print(f"‚ùå L·ªói parser: {e}")
            # Th·ª≠ ƒë·ªçc v·ªõi on_bad_lines='skip'
            print("üîÑ Th·ª≠ ƒë·ªçc v·ªõi skip bad lines...")
            df = pd.read_csv(file_path, on_bad_lines='skip')
            print("‚úÖ ƒê√£ ƒë·ªçc file th√†nh c√¥ng v·ªõi m·ªôt s·ªë d√≤ng b·ªã b·ªè qua")
        
        # 1. KI·ªÇM TRA TH√îNG TIN C∆† B·∫¢N
        print("\n=== TH√îNG TIN C∆† B·∫¢N ===")
        print(f"üìä K√≠ch th∆∞·ªõc d·ªØ li·ªáu: {df.shape[0]} d√≤ng, {df.shape[1]} c·ªôt")
        print(f"üìã T√™n c√°c c·ªôt: {list(df.columns)}")
        
        # 2. KI·ªÇM TRA HEADER
        print("\n=== KI·ªÇM TRA HEADER ===")
        expected_columns = ['timestamp', 'id', 'mac', 'rssi', 'rate', 'sig_mode', 'mcs', 
                          'bandwidth', 'smoothing', 'not_sounding', 'aggregation', 'stbc', 
                          'fec_coding', 'sgi', 'noise_floor', 'ampdu_cnt', 'channel', 
                          'secondary_channel', 'local_timestamp', 'ant', 'sig_len', 
                          'rx_state', 'len', 'first_word', 'data']
        
        missing_cols = set(expected_columns) - set(df.columns)
        extra_cols = set(df.columns) - set(expected_columns)
        
        if missing_cols:
            print(f"‚ö†Ô∏è  Thi·∫øu c·ªôt: {list(missing_cols)}")
        if extra_cols:
            print(f"‚ûï C·ªôt th√™m: {list(extra_cols)}")
        if not missing_cols and not extra_cols:
            print("‚úÖ Header ƒë√∫ng chu·∫©n")
        
        # 3. KI·ªÇM TRA GI√Å TR·ªä THI·∫æU
        print("\n=== KI·ªÇM TRA GI√Å TR·ªä THI·∫æU ===")
        missing_data = df.isnull().sum()
        total_missing = missing_data.sum()
        if total_missing > 0:
            print(f"‚ùå T·ªïng s·ªë gi√° tr·ªã thi·∫øu: {total_missing}")
            for col, count in missing_data[missing_data > 0].items():
                percentage = (count / len(df)) * 100
                print(f"   - {col}: {count} gi√° tr·ªã ({percentage:.2f}%)")
        else:
            print("‚úÖ Kh√¥ng c√≥ gi√° tr·ªã thi·∫øu")
        
        # 4. KI·ªÇM TRA D·ªÆ LI·ªÜU TR√ôNG L·∫∂P
        print("\n=== KI·ªÇM TRA D·ªÆ LI·ªÜU TR√ôNG L·∫∂P ===")
        duplicates = df.duplicated().sum()
        if duplicates > 0:
            print(f"‚ö†Ô∏è  C√≥ {duplicates} d√≤ng tr√πng l·∫∑p ({duplicates/len(df)*100:.2f}%)")
        else:
            print("‚úÖ Kh√¥ng c√≥ d·ªØ li·ªáu tr√πng l·∫∑p")
        
        # 5. KI·ªÇM TRA T√çNH NH·∫§T QU√ÅN C·ª¶A S·ªê C·ªòT
        print("\n=== KI·ªÇM TRA T√çNH NH·∫§T QU√ÅN ===")
        expected_cols_count = len(expected_columns)
        actual_rows_cols = []
        
        # ƒê·ªçc file ƒë·ªÉ ki·ªÉm tra s·ªë c·ªôt t·ª´ng d√≤ng
        with open(file_path, 'r') as f:
            lines = f.readlines()
            for i, line in enumerate(lines[:100]):  # Ki·ªÉm tra 100 d√≤ng ƒë·∫ßu
                cols_count = len(line.strip().split(','))
                if i == 0:  # Header
                    header_cols = cols_count
                else:
                    if cols_count != header_cols:
                        actual_rows_cols.append((i+1, cols_count))
        
        if actual_rows_cols:
            print(f"‚ö†Ô∏è  Ph√°t hi·ªán {len(actual_rows_cols)} d√≤ng c√≥ s·ªë c·ªôt kh√¥ng kh·ªõp:")
            for row_num, col_count in actual_rows_cols[:10]:  # Hi·ªÉn th·ªã 10 d√≤ng ƒë·∫ßu
                print(f"   - D√≤ng {row_num}: {col_count} c·ªôt (mong ƒë·ª£i {header_cols})")
        else:
            print("‚úÖ T·∫•t c·∫£ d√≤ng c√≥ s·ªë c·ªôt nh·∫•t qu√°n")
        
        # 6. KI·ªÇM TRA GI√Å TR·ªä RSSI
        if 'rssi' in df.columns:
            print("\n=== KI·ªÇM TRA GI√Å TR·ªä RSSI ===")
            rssi_values = df['rssi']
            valid_rssi = rssi_values[(rssi_values >= -100) & (rssi_values <= 0)]
            invalid_rssi = len(rssi_values) - len(valid_rssi)
            
            if invalid_rssi > 0:
                print(f"‚ö†Ô∏è  {invalid_rssi} gi√° tr·ªã RSSI kh√¥ng h·ª£p l√Ω (ngo√†i kho·∫£ng -100 ƒë·∫øn 0 dBm)")
                print(f"   - Min: {rssi_values.min()}, Max: {rssi_values.max()}")
            else:
                print("‚úÖ T·∫•t c·∫£ gi√° tr·ªã RSSI h·ª£p l√Ω")
        
        # 7. KI·ªÇM TRA TIMESTAMP
        if 'timestamp' in df.columns:
            print("\n=== KI·ªÇM TRA TIMESTAMP ===")
            try:
                df['timestamp_parsed'] = pd.to_datetime(df['timestamp'])
                print("‚úÖ Timestamp c√≥ ƒë·ªãnh d·∫°ng h·ª£p l·ªá")
                
                # Ki·ªÉm tra t√≠nh li√™n t·ª•c
                time_diff = df['timestamp_parsed'].diff().dropna()
                if len(time_diff) > 0:
                    avg_interval = time_diff.mean()
                    print(f"üìä Kho·∫£ng th·ªùi gian trung b√¨nh gi·ªØa c√°c m·∫´u: {avg_interval}")
                    
                    # T√¨m kho·∫£ng c√°ch b·∫•t th∆∞·ªùng
                    outlier_threshold = avg_interval * 10
                    large_gaps = time_diff[time_diff > outlier_threshold]
                    if len(large_gaps) > 0:
                        print(f"‚ö†Ô∏è  Ph√°t hi·ªán {len(large_gaps)} kho·∫£ng c√°ch th·ªùi gian b·∫•t th∆∞·ªùng")
                    
            except Exception as e:
                print(f"‚ùå L·ªói khi parse timestamp: {e}")
        
        # 8. KI·ªÇM TRA TR∆Ø·ªúNG DATA
        if 'data' in df.columns:
            print("\n=== KI·ªÇM TRA TR∆Ø·ªúNG DATA ===")
            data_sample = df['data'].iloc[0] if len(df) > 0 else None
            if data_sample:
                print(f"üìã M·∫´u d·ªØ li·ªáu CSI ƒë·∫ßu ti√™n: {str(data_sample)[:100]}...")
                
                # Ki·ªÉm tra ƒë·ªãnh d·∫°ng array
                if str(data_sample).startswith('[') and str(data_sample).endswith(']'):
                    print("‚úÖ D·ªØ li·ªáu CSI c√≥ ƒë·ªãnh d·∫°ng array")
                    try:
                        import ast
                        parsed_data = ast.literal_eval(str(data_sample))
                        print(f"üìä S·ªë ph·∫ßn t·ª≠ trong CSI array: {len(parsed_data)}")
                    except:
                        print("‚ö†Ô∏è  Kh√¥ng th·ªÉ parse CSI array")
                else:
                    print("‚ö†Ô∏è  D·ªØ li·ªáu CSI kh√¥ng c√≥ ƒë·ªãnh d·∫°ng array chu·∫©n")
        
        # 9. TH·ªêNG K√ä M√î T·∫¢
        print("\n=== TH·ªêNG K√ä M√î T·∫¢ C√ÅC C·ªòT S·ªê ===")
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            print(df[numeric_cols].describe())
        
        # 10. PH√ÅT HI·ªÜN OUTLIERS
        print("\n=== PH√ÅT HI·ªÜN OUTLIERS ===")
        for col in numeric_cols[:5]:  # Ki·ªÉm tra 5 c·ªôt ƒë·∫ßu ti√™n
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
            
            if len(outliers) > 0:
                print(f"‚ö†Ô∏è  {col}: {len(outliers)} outliers ({len(outliers)/len(df)*100:.2f}%)")
            else:
                print(f"‚úÖ {col}: Kh√¥ng c√≥ outliers")
        
        print(f"\n=== T·ªîNG K·∫æT KI·ªÇM TRA FILE {os.path.basename(file_path)} ===")
        issues = []
        if total_missing > 0:
            issues.append("C√≥ gi√° tr·ªã thi·∫øu")
        if duplicates > 0:
            issues.append("C√≥ d·ªØ li·ªáu tr√πng l·∫∑p")
        if actual_rows_cols:
            issues.append("S·ªë c·ªôt kh√¥ng nh·∫•t qu√°n")
        if missing_cols or extra_cols:
            issues.append("Header kh√¥ng chu·∫©n")
        
        if issues:
            print(f"‚ö†Ô∏è  Ph√°t hi·ªán {len(issues)} v·∫•n ƒë·ªÅ: {', '.join(issues)}")
        else:
            print("‚úÖ D·ªØ li·ªáu c√≥ v·∫ª ·ªïn ƒë·ªãnh!")
            
        return df
        
    except Exception as e:
        print(f"‚ùå L·ªói khi ki·ªÉm tra file: {e}")
        return None

def check_all_csi_files(data_dir="data/csi"):
    """
    Ki·ªÉm tra t·∫•t c·∫£ file CSI trong th∆∞ m·ª•c
    """
    print("=== KI·ªÇM TRA T·∫§T C·∫¢ FILE CSI ===\n")
    
    if not os.path.exists(data_dir):
        print(f"‚ùå Th∆∞ m·ª•c {data_dir} kh√¥ng t·ªìn t·∫°i")
        return
    
    csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]
    
    if not csv_files:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file CSV n√†o trong {data_dir}")
        return
    
    print(f"üìÅ T√¨m th·∫•y {len(csv_files)} file CSV: {csv_files}\n")
    
    for csv_file in csv_files:
        file_path = os.path.join(data_dir, csv_file)
        df = check_csi_data(file_path)
        print("\n" + "="*80 + "\n")

if __name__ == "__main__":
    # Ki·ªÉm tra file c·ª• th·ªÉ
    file_path = "data/csi_format/csi_0m.csv"
    if os.path.exists(file_path):
        check_csi_data(file_path)
    else:
        print(f"‚ùå File {file_path} kh√¥ng t·ªìn t·∫°i")
        
    print("\n" + "="*80)
    
    # Ki·ªÉm tra t·∫•t c·∫£ file trong th∆∞ m·ª•c
    check_all_csi_files("data/csi_format")