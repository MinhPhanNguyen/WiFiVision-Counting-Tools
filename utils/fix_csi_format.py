import pandas as pd
import numpy as np
import os
import re
import ast
from pathlib import Path

def create_output_directory(output_dir="data/csi_format"):
    """
    T·∫°o th∆∞ m·ª•c output n·∫øu ch∆∞a t·ªìn t·∫°i
    """
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    print(f"‚úÖ ƒê√£ t·∫°o th∆∞ m·ª•c: {output_dir}")

def clean_and_parse_line(line):
    """
    L√†m s·∫°ch v√† parse d√≤ng CSV v·ªõi x·ª≠ l√Ω l·ªói ƒë·∫∑c bi·ªát
    """
    # S·ª≠a m·ªôt s·ªë l·ªói th∆∞·ªùng g·∫∑p
    line = line.replace(',1-', ',-')  # S·ª≠a l·ªói 1-14 th√†nh -14
    line = line.replace(',,', ',0,')  # S·ª≠a l·ªói d·∫•u ph·∫©y k√©p
    
    # Parse v·ªõi x·ª≠ l√Ω ƒë·∫∑c bi·ªát cho array
    row_data = []
    current_field = ""
    in_brackets = False
    bracket_count = 0
    
    i = 0
    while i < len(line):
        char = line[i]
        
        if char == '[':
            in_brackets = True
            bracket_count += 1
            current_field += char
        elif char == ']':
            bracket_count -= 1
            current_field += char
            if bracket_count <= 0:
                in_brackets = False
        elif char == ',' and not in_brackets:
            row_data.append(current_field.strip())
            current_field = ""
        else:
            current_field += char
        
        i += 1
    
    # Th√™m field cu·ªëi c√πng
    if current_field.strip():
        row_data.append(current_field.strip())
    
    return row_data

def fix_csi_data_column(row_data, expected_columns=25):
    """
    S·ª≠a ch·ªØa d√≤ng d·ªØ li·ªáu b·ªã t√°ch c·ªôt do tr∆∞·ªùng data
    """
    # N·∫øu s·ªë c·ªôt ƒë√∫ng, return nguy√™n
    if len(row_data) == expected_columns:
        return row_data
    
    # N·∫øu s·ªë c·ªôt > expected, g·ªôp ph·∫ßn th·ª´a v√†o tr∆∞·ªùng data (c·ªôt cu·ªëi)
    if len(row_data) > expected_columns:
        # L·∫•y 24 c·ªôt ƒë·∫ßu (tr·ª´ data)
        fixed_data = row_data[:expected_columns-1]
        
        # G·ªôp t·∫•t c·∫£ c·ªôt th·ª´a th√†nh tr∆∞·ªùng data
        remaining_data = row_data[expected_columns-1:]
        
        # T·∫°o l·∫°i array CSI t·ª´ c√°c c·ªôt b·ªã t√°ch
        try:
            # G·ªôp t·∫•t c·∫£ remaining data th√†nh m·ªôt string
            combined_data = ','.join(remaining_data)
            
            # L√†m s·∫°ch v√† t·∫°o l·∫°i array
            # Lo·∫°i b·ªè d·∫•u [ ] th·ª´a
            combined_data = combined_data.replace('[', '').replace(']', '')
            
            # Split v√† clean t·ª´ng s·ªë
            numbers = []
            for item in combined_data.split(','):
                item = item.strip()
                if item:
                    try:
                        # S·ª≠a l·ªói s·ªë √¢m b·ªã d√≠nh
                        item = item.replace('1-', '-')
                        num_val = float(item)
                        numbers.append(int(num_val) if num_val.is_integer() else num_val)
                    except ValueError:
                        # B·ªè qua item kh√¥ng convert ƒë∆∞·ª£c
                        continue
            
            # T·∫°o l·∫°i array string
            if numbers:
                data_array_str = '[' + ','.join(map(str, numbers)) + ']'
            else:
                data_array_str = '[]'
                
        except Exception as e:
            print(f"‚ö†Ô∏è  L·ªói khi x·ª≠ l√Ω data array: {e}")
            data_array_str = '[]'
        
        # Th√™m data ƒë√£ s·ª≠a v√†o cu·ªëi
        fixed_data.append(data_array_str)
        return fixed_data
    
    # N·∫øu s·ªë c·ªôt < expected, th√™m c·ªôt tr·ªëng
    else:
        missing_cols = expected_columns - len(row_data)
        return row_data + [''] * missing_cols

def validate_and_fix_rssi(rssi_value):
    """
    Validate v√† s·ª≠a gi√° tr·ªã RSSI
    RSSI h·ª£p l√Ω: -100 ƒë·∫øn 0 dBm
    """
    try:
        rssi = float(rssi_value)
        
        # N·∫øu gi√° tr·ªã d∆∞∆°ng, chuy·ªÉn th√†nh √¢m
        if rssi > 0:
            rssi = -rssi
            
        # Gi·ªõi h·∫°n trong kho·∫£ng h·ª£p l√Ω
        if rssi < -100:
            rssi = -100
        elif rssi > 0:
            rssi = 0
            
        return int(rssi)
    except (ValueError, TypeError):
        return -50  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh

def validate_and_fix_numeric_field(value, field_name, min_val=None, max_val=None, default_val=0):
    """
    Validate v√† s·ª≠a c√°c tr∆∞·ªùng s·ªë
    """
    try:
        num_val = float(value)
        
        if min_val is not None and num_val < min_val:
            return min_val
        if max_val is not None and num_val > max_val:
            return max_val
            
        return int(num_val) if num_val.is_integer() else num_val
    except (ValueError, TypeError):
        return default_val

def fix_timestamp_format(timestamp_str):
    """
    S·ª≠a ƒë·ªãnh d·∫°ng timestamp
    """
    try:
        # Ki·ªÉm tra v√† s·ª≠a ƒë·ªãnh d·∫°ng timestamp
        if pd.isna(timestamp_str) or str(timestamp_str).strip() == '':
            return pd.Timestamp.now().isoformat()
        
        # Th·ª≠ parse timestamp
        parsed_time = pd.to_datetime(timestamp_str)
        return parsed_time.isoformat()
    except:
        return pd.Timestamp.now().isoformat()

def fix_csi_file(input_file, output_file):
    """
    S·ª≠a ch·ªØa m·ªôt file CSI
    """
    print(f"\nüîß ƒêang s·ª≠a file: {input_file}")
    
    try:
        # ƒê·ªçc file CSV v·ªõi x·ª≠ l√Ω l·ªói
        lines_read = 0
        lines_fixed = 0
        fixed_data = []
        
        expected_columns = ['timestamp', 'id', 'mac', 'rssi', 'rate', 'sig_mode', 'mcs', 
                          'bandwidth', 'smoothing', 'not_sounding', 'aggregation', 'stbc', 
                          'fec_coding', 'sgi', 'noise_floor', 'ampdu_cnt', 'channel', 
                          'secondary_channel', 'local_timestamp', 'ant', 'sig_len', 
                          'rx_state', 'len', 'first_word', 'data']
        
        # Th√™m header
        fixed_data.append(expected_columns)
        
        # ƒê·ªçc t·ª´ng d√≤ng v√† s·ª≠a
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            
        for i, line in enumerate(lines):
            lines_read += 1
            
            # B·ªè qua header
            if i == 0:
                continue
                
            # Parse d√≤ng CSV
            line = line.strip()
            if not line:
                continue
                
            try:
                # Parse d√≤ng CSV v·ªõi x·ª≠ l√Ω ƒë·∫∑c bi·ªát
                row_data = clean_and_parse_line(line)
                
                # S·ª≠a ch·ªØa s·ªë c·ªôt
                fixed_row = fix_csi_data_column(row_data, len(expected_columns))
                
                # Validate v√† s·ª≠a t·ª´ng tr∆∞·ªùng
                if len(fixed_row) >= len(expected_columns):
                    # Timestamp
                    fixed_row[0] = fix_timestamp_format(fixed_row[0])
                    
                    # ID - s·ªë nguy√™n
                    fixed_row[1] = validate_and_fix_numeric_field(fixed_row[1], 'id', 0, 100000, 0)
                    
                    # MAC address - gi·ªØ nguy√™n
                    # fixed_row[2] = fixed_row[2]
                    
                    # RSSI - s·ª≠a ƒë·∫∑c bi·ªát
                    fixed_row[3] = validate_and_fix_rssi(fixed_row[3])
                    
                    # Rate
                    fixed_row[4] = validate_and_fix_numeric_field(fixed_row[4], 'rate', 0, 1000, 11)
                    
                    # C√°c tr∆∞·ªùng boolean (0 ho·∫∑c 1)
                    bool_fields = [5, 7, 8, 9, 10, 11, 12, 13]  # sig_mode, bandwidth, smoothing, etc.
                    for idx in bool_fields:
                        if idx < len(fixed_row):
                            val = validate_and_fix_numeric_field(fixed_row[idx], f'field_{idx}', 0, 1, 0)
                            fixed_row[idx] = 1 if val > 0 else 0
                    
                    # MCS
                    if len(fixed_row) > 6:
                        fixed_row[6] = validate_and_fix_numeric_field(fixed_row[6], 'mcs', 0, 15, 4)
                    
                    # Noise floor
                    if len(fixed_row) > 14:
                        fixed_row[14] = validate_and_fix_numeric_field(fixed_row[14], 'noise_floor', -120, -50, -96)
                    
                    # Channel
                    if len(fixed_row) > 16:
                        fixed_row[16] = validate_and_fix_numeric_field(fixed_row[16], 'channel', 1, 14, 1)
                    
                    # Secondary channel
                    if len(fixed_row) > 17:
                        fixed_row[17] = validate_and_fix_numeric_field(fixed_row[17], 'secondary_channel', 0, 2, 2)
                    
                    # Validate data array
                    if len(fixed_row) > 24:
                        data_str = str(fixed_row[24])
                        if not (data_str.startswith('[') and data_str.endswith(']')):
                            fixed_row[24] = '[]'
                    
                    fixed_data.append(fixed_row[:len(expected_columns)])
                    lines_fixed += 1
                else:
                    print(f"‚ö†Ô∏è  D√≤ng {i+1}: Kh√¥ng th·ªÉ s·ª≠a ƒë∆∞·ª£c (ch·ªâ c√≥ {len(fixed_row)} c·ªôt)")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è  L·ªói d√≤ng {i+1}: {e}")
                continue
        
        # Ghi file ƒë√£ s·ª≠a
        with open(output_file, 'w', encoding='utf-8', newline='') as f:
            for row in fixed_data:
                f.write(','.join(map(str, row)) + '\n')
        
        print(f"‚úÖ ƒê√£ s·ª≠a xong: {lines_read} d√≤ng ƒë·ªçc, {lines_fixed} d√≤ng s·ª≠a th√†nh c√¥ng")
        print(f"üìÅ File ƒë√£ l∆∞u: {output_file}")
        
        # Validate file ƒë√£ s·ª≠a
        try:
            # S·ª≠ d·ª•ng on_bad_lines='skip' ƒë·ªÉ b·ªè qua d√≤ng l·ªói khi validation
            df_check = pd.read_csv(output_file, on_bad_lines='skip')
            print(f"‚úÖ Validation: {df_check.shape[0]} d√≤ng, {df_check.shape[1]} c·ªôt")
            
            # Ki·ªÉm tra RSSI
            rssi_invalid = df_check[(df_check['rssi'] > 0) | (df_check['rssi'] < -100)]
            print(f"üìä RSSI h·ª£p l·ªá: {len(df_check) - len(rssi_invalid)}/{len(df_check)} d√≤ng")
            
            return True
        except Exception as e:
            print(f"‚ùå L·ªói validation: {e}")
            return False
            
    except Exception as e:
        print(f"‚ùå L·ªói khi s·ª≠a file {input_file}: {e}")
        return False

def fix_all_csi_files(input_dir="data/csi", output_dir="data/csi_format"):
    """
    S·ª≠a ch·ªØa t·∫•t c·∫£ file CSI trong th∆∞ m·ª•c
    """
    print("üöÄ B·∫ÆT ƒê·∫¶U S·ª¨A CH·ªÆA T·∫§T C·∫¢ FILE CSI")
    print("="*60)
    
    # T·∫°o th∆∞ m·ª•c output
    create_output_directory(output_dir)
    
    # T√¨m t·∫•t c·∫£ file CSV
    if not os.path.exists(input_dir):
        print(f"‚ùå Th∆∞ m·ª•c {input_dir} kh√¥ng t·ªìn t·∫°i")
        return
    
    csv_files = [f for f in os.listdir(input_dir) if f.endswith('.csv')]
    
    if not csv_files:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file CSV n√†o trong {input_dir}")
        return
    
    print(f"üìÅ T√¨m th·∫•y {len(csv_files)} file CSV: {csv_files}")
    
    success_count = 0
    failed_count = 0
    
    for csv_file in csv_files:
        input_path = os.path.join(input_dir, csv_file)
        output_path = os.path.join(output_dir, csv_file)
        
        if fix_csi_file(input_path, output_path):
            success_count += 1
        else:
            failed_count += 1
        
        print("-" * 60)
    
    print(f"\nüéâ HO√ÄN TH√ÄNH S·ª¨A CH·ªÆA")
    print(f"‚úÖ Th√†nh c√¥ng: {success_count} file")
    print(f"‚ùå Th·∫•t b·∫°i: {failed_count} file")
    print(f"üìÅ File ƒë√£ s·ª≠a ƒë∆∞·ª£c l∆∞u trong: {output_dir}")

def generate_summary_report(output_dir="data/csi_format"):
    """
    T·∫°o b√°o c√°o t√≥m t·∫Øt sau khi s·ª≠a
    """
    print(f"\nüìä T·∫†O B√ÅO C√ÅO T√ìNG T·∫ÆT")
    print("="*60)
    
    if not os.path.exists(output_dir):
        print(f"‚ùå Th∆∞ m·ª•c {output_dir} kh√¥ng t·ªìn t·∫°i")
        return
    
    csv_files = [f for f in os.listdir(output_dir) if f.endswith('.csv')]
    
    report_data = []
    
    for csv_file in csv_files:
        file_path = os.path.join(output_dir, csv_file)
        try:
            df = pd.read_csv(file_path, on_bad_lines='skip')  # B·ªè qua d√≤ng l·ªói
            
            # Th·ªëng k√™ c∆° b·∫£n
            total_rows = len(df)
            total_cols = len(df.columns)
            missing_values = df.isnull().sum().sum()
            
            # Th·ªëng k√™ RSSI
            rssi_valid = len(df[(df['rssi'] >= -100) & (df['rssi'] <= 0)])
            rssi_invalid = total_rows - rssi_valid
            
            # Th·ªëng k√™ data field
            data_valid = 0
            if 'data' in df.columns:
                for data_val in df['data'].head(10):  # Ki·ªÉm tra 10 d√≤ng ƒë·∫ßu
                    if str(data_val).startswith('[') and str(data_val).endswith(']'):
                        data_valid += 1
            
            report_data.append({
                'File': csv_file,
                'D√≤ng': total_rows,
                'C·ªôt': total_cols,
                'Gi√° tr·ªã thi·∫øu': missing_values,
                'RSSI h·ª£p l·ªá': f"{rssi_valid}/{total_rows}",
                'Data array OK': f"{data_valid}/10 m·∫´u"
            })
            
        except Exception as e:
            report_data.append({
                'File': csv_file,
                'D√≤ng': 'ERROR',
                'C·ªôt': 'ERROR',
                'Gi√° tr·ªã thi·∫øu': 'ERROR',
                'RSSI h·ª£p l·ªá': 'ERROR',
                'Data array OK': 'ERROR'
            })
    
    # In b√°o c√°o
    print(f"{'File':<15} {'D√≤ng':<8} {'C·ªôt':<5} {'Thi·∫øu':<8} {'RSSI OK':<12} {'Data OK':<12}")
    print("-" * 70)
    
    for item in report_data:
        print(f"{item['File']:<15} {item['D√≤ng']:<8} {item['C·ªôt']:<5} {item['Gi√° tr·ªã thi·∫øu']:<8} {item['RSSI h·ª£p l·ªá']:<12} {item['Data array OK']:<12}")

if __name__ == "__main__":
    print("üîß SCRIPT S·ª¨A CH·ªÆA D·ªÆ LI·ªÜU CSI")
    print("="*60)
    
    # S·ª≠a t·∫•t c·∫£ file
    fix_all_csi_files("data/csi", "data/csi_format")
    
    # T·∫°o b√°o c√°o
    generate_summary_report("data/csi_format")
    
    print("\nüéØ H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG FILE ƒê√É S·ª¨A:")
    print("1. S·ª≠ d·ª•ng pandas.read_csv() b√¨nh th∆∞·ªùng")
    print("2. RSSI ƒë√£ ƒë∆∞·ª£c normalize v·ªÅ kho·∫£ng -100 ƒë·∫øn 0 dBm")
    print("3. Tr∆∞·ªùng 'data' ƒë√£ ƒë∆∞·ª£c format l·∫°i th√†nh array string")
    print("4. C√°c gi√° tr·ªã thi·∫øu ƒë√£ ƒë∆∞·ª£c ƒëi·ªÅn default")
    print("5. File g·ªëc ƒë∆∞·ª£c gi·ªØ nguy√™n trong data/csi/")
